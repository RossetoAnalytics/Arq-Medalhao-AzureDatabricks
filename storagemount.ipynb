{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d83e50e-544f-445f-b199-591a686e72cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted the directory '[target_mount_point]' .\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/bronze\"\n",
    "\n",
    "configs = {\n",
    "\t\"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "\t\"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = \"abfss://bronze@storagedataengproject.dfs.core.windows.net/\",\n",
    "mount_point = target_mount_point,\n",
    "extra_configs = configs)\n",
    "print(f\"Mounted the directory '[target_mount_point]' .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68020b93-f21b-40b7-9ad5-ac7cd9df39e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted the directory '[target_mount_point]' .\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/silver\"\n",
    "\n",
    "configs = {\n",
    "\t\"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "\t\"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = \"abfss://silver@storagedataengproject.dfs.core.windows.net/\",\n",
    "mount_point = target_mount_point,\n",
    "extra_configs = configs)\n",
    "print(f\"Mounted the directory '[target_mount_point]' .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8adf0586-35d2-47c7-a77f-364de4393dc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted the directory '[target_mount_point]' .\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/gold\"\n",
    "\n",
    "configs = {\n",
    "\t\"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "\t\"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = \"abfss://gold@storagedataengproject.dfs.core.windows.net/\",\n",
    "mount_point = target_mount_point,\n",
    "extra_configs = configs)\n",
    "print(f\"Mounted the directory '[target_mount_point]' .\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "storagemount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
